{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Биомедицинские нанотехнологии и компьютерное зрение (Computer Vision) \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Трекинг объектов на изображении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video analysis (video module)\n",
    "# https://docs.opencv.org/3.4/da/dd0/tutorial_table_of_content_video.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='justify'>В данном модуле рассмотрим ещё одно важное понятие в области компьютерного зрения, которое называется трекингом или отслеживанием (Tracking). Отслеживание - это задача определения положения объекта на последовательности изображений. Чаще всего данная задача применима именно к потоковому видео. В частности, отслеживание может быть выполнено в случае детекции одного или нескольких объектов одновременно. В этом модуле мы рассмотрим оба метода отслеживания объектов на изображении.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width='35%' src='img/cell_move_short.gif'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='justify'>Методы отслеживания нашли широкое применение в таких приложениях, как распознавание действий, автомобили с автопилотом, охрана и видеонаблюдение, приложения дополненной реальности (AR) и системы детекции движения. Например, в приложениях дополненной реальности, когда необходимо нарисовать трёхмерный объект на плоскости. Достаточно распространённой задачей является мониторинг дорожного движения, отслеживание транспортных средств и учет номерных знаков, что позволяет управлять дорожным движением и контролировать безопасность.<br>\n",
    "В биологии и медицине данный подход можно использовать для анализа движений микроорганизмов и детекции движения структурных элементов различных жидкостей.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='justify'><b>Основные проблемы трекинга.</b><br>\n",
    "\n",
    "• Скрытие объекта. Целевой объект может быть скрыт за другими объектами в последовательности изображений. Для отслеживание требуется его  выделение на фоне остальных объектов.\n",
    "\n",
    "• Быстрое перемещение. Перемещение объекта может приводить к размытию границ между объектом и фоном. В этом случае требуется использование дорогих камер, позволяющих снимать видео в высоком разрешении. \n",
    "\n",
    "• Изменение формы. Если объект способен изменять форму, то подобная деформация приводит к невозможности обнаружения объекта, а также к проблеме отслеживания. \n",
    "\n",
    "• Ложные срабатывания. Га изображении с несколькими близкими по форме объектами трудно выделить тот, который нас интересует. Трекер может потерять текущий объект и начать отслеживать ложный объект.\n",
    "</div><br>\n",
    "<div align='justify'>\n",
    "Далее будет рассмотрена программная реализация методов трекинга объектов в библиотеке OpenCV. Мы рассмотрим трекинг на основе вычитания фона (Background Subtraction) и на основе среднего сдвига (Meanshift).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='justify'>Перед рассмотрением методов детекции объектов создадим тестовое видео с движущимся объектом. Будем использовать следующую программу:<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Программа для создания тестового изображения\n",
    "\n",
    "import cv2 as cv\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# Создание изображения\n",
    "# fig = plt.figure(figsize=(5, 5))                      \n",
    "# ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# Будем использовать окружность с диаметром 2.5 у.е.\n",
    "# Траектория движения описывается тригонометрической функцией синуса с частотой f = 1 Гц\n",
    "# Функция для изменения координаты объекта на изображении\n",
    "def ani_func(i):\n",
    "    ax.clear()\n",
    "    x = i*0.01\n",
    "    y = 2.5*math.sin(2*3.14*x)\n",
    "    circle = plt.Circle((x, y), 0.25, color='g')\n",
    "    plt.gca().add_patch(circle)\n",
    "    ax.set_xlim([0, 10])\n",
    "    ax.set_ylim([-5, 5])\n",
    "    ax.axis('off')\n",
    "\n",
    "# Анимирование изображения и сохранение в файл *.mp4\n",
    "# ani = animation.FuncAnimation(fig, ani_func, frames=1000, interval=10, repeat=False)\n",
    "# ani.save('animate_circle_sin.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Отслеживание траектории движения на основе вычитания фона (Background Subtraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background Subtraction Methods \n",
    "# https://docs.opencv.org/3.4/d1/dc5/tutorial_background_subtraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='justify'>Вычитание фона (Background Subtraction) - это метод для создания маски переднего плана (точнее двоичного изображения, содержащего пиксели движущимся объектам в сцене), основанный на использовании статичных камер.\n",
    "Метод вычитания фона вычисляет маску переднего плана, выполняя вычитание между текущим кадром и фоновым изображением (background model). Результатом обработки является выделение объекта на изображении. После бинаризации интересуемый объект будет белым. Ниже показан результат работы метода вычитания.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/bst_scheme.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='justify'>На первом шаге вычисляется модель (фон) для объекта на изображении. На втором шаге данная модель обновляется, чтобы адаптироваться к возможным изменениям на изображении. Далее рассмотрим пример программы для трекинга на основе вычитания фона (Background Subtraction).</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Программа для трекинга на основе вычитания фона (Background Subtraction)\n",
    "\n",
    "# Создание объекта\n",
    "fgbg = cv.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Захват кадров из видео\n",
    "capture = cv.VideoCapture('data/lab_3/animate_circle_sin.mp4')\n",
    "\n",
    "while True:\n",
    "\n",
    "    # Чтение кадров\n",
    "    ret, frame = capture.read();\n",
    "    if frame is None:\n",
    "        break\n",
    "        \n",
    "    # Применение маски для вычитания фона\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    cv.imshow('Original image', frame)\n",
    "    cv.imshow('MOG image', fgmask)\n",
    "   \n",
    "    # Выход из потока при нажатии `q`\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Отслеживание траектории движения на основе поиска и анализа контуров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Программа для трекинга на основе анализа контуров\n",
    "\n",
    "# Создание объекта\n",
    "fgbg = cv.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Захват кадров из видео\n",
    "capture = cv.VideoCapture('data/lab_3/animate_circle_sin.mp4')\n",
    "\n",
    "data = []\n",
    "\n",
    "while True:\n",
    "\n",
    "    # Чтение кадров\n",
    "    ret, frame = capture.read();\n",
    "    if frame is None:\n",
    "        break\n",
    "\n",
    "    # Преобразование кадра BGR -> RGB -> GRAY\n",
    "    img_rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    imgray = cv.cvtColor(img_rgb, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Поиск контуров на изображении\n",
    "    ret, thresh = cv.threshold(imgray, 155, 255, 0)\n",
    "    contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    cnt = contours[1]\n",
    "    \n",
    "    # Отрисовка окружности    \n",
    "    (x,y), radius = cv.minEnclosingCircle(cnt)\n",
    "    center = (int(x), int(y))\n",
    "    radius = int(radius) + 5\n",
    "    cv.circle(frame, center, radius, (0, 255, 0), 2)\n",
    "    \n",
    "    # Отрисовка прямоугольника\n",
    "    x, y, w, h = cv.boundingRect(cnt)\n",
    "    cv.rectangle(frame, (x,y), (x+h,y+w), (0, 255, 0), 1)\n",
    "    \n",
    "    # Вывод на экран координат центра объекта\n",
    "    cv.putText(frame, \"circle\", (10, 10),\n",
    "                cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "    \n",
    "    cv.putText(frame, f'x, y = {round(x, 2), round(y, 2)}', (20, 40),\n",
    "                cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "    \n",
    "    # Отрисовка траектории движения\n",
    "    data.append([x, y])\n",
    "    image = cv.polylines(frame, [np.array(data) ], False, (255, 0, 0), 2)\n",
    "    \n",
    "    cv.imshow(f'Original video', img_rgb)\n",
    "    cv.imshow(f'Tracking video', frame)\n",
    "    \n",
    "    # Выход из потока при нажатии `q`\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Отслеживание траектории движения на основе анализа среднего значения (Meanshift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meanshift and Camshift\n",
    "# https://docs.opencv.org/3.4/d7/d00/tutorial_meanshift.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='justify'>Сдвиг среднего значения (Meanshift) - метод отслеживания траектории движения объекта, который основан на анализе плотности распределения пикселей на изображении. На изображении выделяется небольшое окно в виде круга. Задача программы переместить круг в область, которая имеет максимальную плотность.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width='60%' src='img/meanshift.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='justify'>Исходное положение окна представлено в виде синего круга \"C1\", а его изначальный центр обозначен как синий прямоугольник \"C1_о\". Если найти центроид всех точек в пределах этого окна, то мы получим точку \"C1_r\", обозначенную маленьким синим кругом. Безусловно, эти две точки не будут совпадать. Поэтому нам следует переместить окно таким образом, чтобы центр нового окна совпадал с предыдущим центроидом. Затем мы вновь находим новый центроид и повторяем процесс до тех пор, пока центр окна и его центроид не окажутся в одной и той же точке в пределах погрешности. В итоге мы получаем окно с наибольшим распределением пикселей, обозначенное зелёным кругом с пометкой \"C2\", которое имеет наибольшую плотность пикселей, как это видно на изображении.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='justify'>Далее рассмотрим пример программы для трекинга на основе сдвига среднего значения (Meanshift).</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Программа для трекинга на основе анализа среднего значения\n",
    "\n",
    "# Захват кадров из видео\n",
    "capture = cv.VideoCapture('data/lab_3/animate_circle_sin.mp4')\n",
    "# capture = cv2.VideoCapture('data/lab_3/cell_move_short.mp4')\n",
    "\n",
    "\n",
    "# Чтение кадров для отслеживаемого кадра по ROI\n",
    "# ROI - region of interest (интересуемая область)\n",
    "ret, frame = capture.read()\n",
    "\n",
    "# Создание ROI\n",
    "x,y,w,h = cv.selectROI(frame)\n",
    "track_window = (x, y, w, h)\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "hsv_roi =  cv.cvtColor(roi, cv.COLOR_BGR2HSV)\n",
    "\n",
    "# Применение ROI\n",
    "mask = cv.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "roi_hist = cv.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "cv.normalize(roi_hist,roi_hist,0,255,cv.NORM_MINMAX)\n",
    "term_crit = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "while True:\n",
    "    # Чтение кадров\n",
    "    ret, frame = capture.read()\n",
    "    if ret == True:\n",
    "        \n",
    "        # Перевод из схемы BGR в HSV\n",
    "        hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "        dst = cv.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "        \n",
    "        # Смещение трекера на изображении\n",
    "        ret, track_window = cv.meanShift(dst, track_window, term_crit)\n",
    "        x,y,w,h = track_window\n",
    "        img = cv.rectangle(frame, (x,y), (x+w,y+h), 255,2)\n",
    "        cv.imshow('img', img)  \n",
    "        \n",
    "        # Выход из потока при нажатии `q`\n",
    "        if cv.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='justify'>Рекомендуется самостоятельно разобрать метод на основе анализа оптического потока (Optical Flow) и на основе корреляционной фильтрации (Kernelized Correlation Filter). Для пакетного использования трекеров можно воспользоваться Tracking API</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание для самостоятельной работы.\n",
    "\n",
    "1. Объясните, что такое трекинг и где он может быть использован. Перечислите основные проблемы, которые связаны с трекингом. Какие основные методы для определения траектории движения вы можете назвать.\n",
    "\n",
    "2. Создайте с помощью функции ani_func() функцию, которая позволит смоделировать траекторию движение квадрата. Траектория движения описывается тригонометрической функцией косинуса с частотой f = 0.5 Гц, амплитудой А = 4 от.ед. Частота дискритизации  кадров анимации составляет 100 Гц.\n",
    "\n",
    "3. Проанализируйте с помощью библиотеки OpenCV и метода вычитания фона (Background Subtraction) тестовые видео. Предлагается два видео, на которых необходимо отследить траекторию движения объекта(ов). Используйте видео animate_1_circle.mp4 и animate_2_circle.mp4.\n",
    "\n",
    "4. Проанализируйте с помощью библиотеки OpenCV и метода контурного анализа тестовые видео. Предлагается три видео, на которых необходимо отследить траекторию движения объекта. Далее нужно сохранить траектории движения для каждого видео. Потом проанализировать полученные ряды, используя преобразование Фурье. Определить основные частоты в спектре. Частота дискритизации кадров анимации составляет 100 Гц. Используйте видео circle_1_sample.mp4, circle_2_sample.mp4 и circle_3_sample.mp4.\n",
    "\n",
    "5. Проанализируйте с помощью библиотеки OpenCV и метода на основе анализа среднего значения (Meanshift) тестовое видео. Выберите для отслеживания траектории любой объект. Сохраните траекторию движения в отдельный файл. Используйте видео cell_move_short.mp4. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
